---
title: 'Homework 3: Categorical Data'
author: "Nicholas G Reich, for Biostats 743 at UMass-Amherst"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, eval=FALSE)
```

Your assignment should be submitted in two separate files by 8am on Wednesday October 4th. The first, should be an RMarkdown (.Rmd) or another format that dynamically compiles your write up and runs the code inside it. The second should be the PDF file that was reproducibly compiled using the first file. All figures should be generated by the code, none should be loaded directly. The homework files should be submitted using your shared Google Drive folder with the instructor. 


# Understanding likelihood-based inference

## Question 1

Assume the following data generation model and write code to simulate data from this model:
$$ Y_i \sim Poisson(\mu_i) $$
where 
$$log \mu_i = \alpha + \beta \cdot x_i$$
Fix $\alpha=log(15)$, $\beta = log(2)$, and draw $x_i$ independently from the distribution $Unif(0, 20)$ for $i=1, ..., N$.

(a) Simulate $N=500$ observations from this model. Plot the data in a reasonable way.
(b) Fit a Poisson log-linear GLM to the data.
(c) Write a function that can calculate the likelihood of your data given $(\alpha, \beta)$. Across a fine grid of possible values for $\alpha$ and $\beta$, compute the likelihood for each point. Plot the resulting likelihood surface, showing the MLE, contour lines representing the 80% and 95% likelihood based credible regions, and the estimated 80% and 95% confidence ellipses based on the estimated asymptotic covariance of $(\hat\alpha, \hat\beta)$.
(d) Repeat a-c for a new sample of $N=20$.
(e) Describe your results, with particular attention paid to (i) comparisons between the confidence/credible regions for each of the two sample sizes, and (ii) any differences you observe across the two different samples of data. Note: be sure to use `set.seed()` to ensure your results and interpretations are reproducible and consistent when you re-knit the file. 
(e) Re-run the code for (d) 10 times (with different samples of $y$ each time, hold $x$ fixed across the iterations) and qualitatively assess the sensitivity of your results in (d) and interpretations in (e). Do your results change substantially with each new sample?

## Question 2

Gibbs sampling with censoring? ARM (402).
